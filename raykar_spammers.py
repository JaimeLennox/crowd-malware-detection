import data
import threshold
import numpy as np
import matplotlib.pyplot as plt


show_graphs = True
verbose = True


def run_raykar(engine_count, data_dict, type_dict):
    print "Raykar (Eliminating Spammers) Method:"

    results, learned_sensitivity, learned_specificity = raykar(engine_count, data_dict, type_dict)
    accuracy = data.correct_count(results, type_dict) / float(len(data_dict))

    print "Accuracy:", accuracy

    if show_graphs:
        true_sensitivity, true_specificity = data.annotator_model(engine_count, data_dict, type_dict)

        plt.xlim(0, 1)
        plt.ylim(0, 1)

        plt.xlabel("True Sensitivity")
        plt.ylabel("Learned Sensitivity")

        plt.plot(true_sensitivity, learned_sensitivity, 'o')
        plt.show()

        plt.xlim(0, 1)
        plt.ylim(0, 1)

        plt.xlabel("True Sensitivity")
        plt.ylabel("Learned Sensitivity")

        plt.plot(true_specificity, learned_specificity, 'o')
        plt.show()


def raykar(engine_count, data_dict, type_dict):

    # Initialise by majority voting
    mu = threshold.majority_vote(data_dict)

    # Initialisation
    N = len(mu)
    R = engine_count

    A = set(range(R))

    a1 = 3
    a2 = 2
    b1 = 3
    b2 = 2

    p1 = 2
    p2 = 2

    sensitivity = np.zeros(R)
    specificity = np.zeros(R)

    a = {}
    b = {}

    old_A = set()

    prune_threshold = 2

    while A != old_A:
        old_A = set(A)
        mu_diff = 1

        while mu_diff > 0:
            # EM iteration
            for j in A:
                sum_mu = sum([v if data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])
                sum_neg_mu = sum([(1 - v) if data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])

                sum_mu_y = sum([v * data_dict[k][j] if data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])
                sum_neg_mu_y = sum([(1 - v) * (1 - data_dict[k][j]) if data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])

                sensitivity[j] = (a1 - 1 + sum_mu_y) / float(a1 + a2 - 2 + sum_mu)
                specificity[j] = (b1 - 1 + sum_neg_mu_y) / float(b1 + b2 - 2 + sum_neg_mu)

            prevalence = calculate_prevalence(mu, p1, p2)
            difference = dict(mu)

            for i in data_dict:

                log_a = 0
                log_b = 0

                indices = [index for index, x in enumerate(data_dict[i]) if x < 2 and index in A]

                for j in indices:
                    y = data_dict[i][j]
                    log_a += np.log((sensitivity[j] ** y) * ((1 - sensitivity[j]) ** (1 - y)))
                    log_b += np.log((specificity[j] ** (1 - y)) * ((1 - specificity[j]) ** y))

                a[i] = np.exp(log_a)
                b[i] = np.exp(log_b)

                mu[i] = int(round((a[i] * prevalence) / (a[i] * prevalence + (b[i] * (1 - prevalence)))))
                difference[i] = abs(difference[i] - mu[i])

            mu_diff = sum(difference.values())

            if verbose:
                accuracy = data.correct_count(mu, type_dict) / float(N)
                print accuracy

        spam_score = {}

        for j in A:
            spam_score[j] = lambda_j(sensitivity[j], specificity[j])

        print spam_score

        for i in old_A:
            if spam_score[i] < prune_threshold:
                print "Removed engine", i
                A.remove(i)

    return mu, sensitivity, specificity


def calculate_prevalence(mu, p1, p2):
    sum_mu = sum([v for v in mu.values()])
    return (p1 - 1 + sum_mu) / float(p1 + p2 - 2 + len(mu))


def lambda_j(sensitivity, specificity):
    return 1 / float((sensitivity + specificity - 1) ** 2)


if __name__ == "__main__":
    engine_count, data_dict, type_dict = data.get_large_data()
    run_raykar(engine_count, data_dict, type_dict)











