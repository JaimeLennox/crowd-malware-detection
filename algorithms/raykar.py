import numpy as np
import random
import sys
from math import erf
from numpy.linalg import cond
from scipy.linalg import block_diag, inv

from algorithms import threshold
from utils import data


class Raykar:
    show_graphs = True
    verbose = True

    def __init__(self, engine_count, data_dict, type_dict):
        self._engine_count = engine_count
        self._data_dict = data_dict
        self._type_dict = type_dict

        self._sum_mu = np.zeros(engine_count)
        self._sum_neg_mu = np.zeros(engine_count)
        self._sum_mu_y = np.zeros(engine_count)
        self._sum_neg_mu_y = np.zeros(engine_count)

    def run_core_method(self):
        print "Raykar Method:"

        A = set(range(self._engine_count))
        self._print_results(*self._core_raykar(A, set()))

    def run_semi_supervised_method(self):
        print "Raykar (Semi-Supervised) Method:"

        supervised_proportion = 0.2
        supervised = set()

        for i in self._data_dict:
            if random.random() < supervised_proportion:
                supervised.add(i)

        A = set(range(self._engine_count))
        self._print_results(*self._core_raykar(A, supervised))

    def run_spammers_method(self):
        print "Raykar (Eliminating Spammers) Method:"

        N = len(self._data_dict)
        R = self._engine_count

        mu = {}
        sensitivity = []
        specificity = []

        A = set(range(R))
        old_A = set()

        lambda_j = np.ones(R) * 0.1 * N
        prune_threshold = 0.1 * N

        while A != old_A:
            old_A = set(A)

            mu, sensitivity, specificity = self._core_raykar(A, set())
            lambda_j = self._calculate_lambda_j(sensitivity, specificity, lambda_j)

            for i in old_A:
                if lambda_j[i] > prune_threshold:
                    if self.verbose:
                        print "Removed engine", i
                    A.remove(i)

        self._print_results(mu, sensitivity, specificity)

    def _print_results(self, results, learned_sensitivity, learned_specificity):
        accuracy = data.correct_count(results, self._type_dict) / float(len(self._data_dict))

        print "Accuracy:", accuracy

        if self.show_graphs:
            true_sensitivity, true_specificity = data.annotator_model(self._engine_count, self._data_dict, self._type_dict)
            data.sensitivity_graph(learned_sensitivity, true_sensitivity)
            data.specificity_graph(learned_specificity, true_specificity)

    def _core_raykar(self, A, supervised):
        # Initialise by majority voting
        mu = threshold.majority_vote(self._data_dict)

        # Initialisation
        N = len(mu)
        R = self._engine_count

        a1 = 3
        a2 = 2
        b1 = 3
        b2 = 2

        a = {}
        b = {}

        p1 = 2
        p2 = 2

        sensitivity = np.zeros(R)
        specificity = np.zeros(R)

        mu_diff = 1

        while mu_diff > 0:
            sum_mu = np.zeros(R)
            sum_mu_y = np.zeros(R)
            sum_neg_mu= np.zeros(R)
            sum_neg_mu_y = np.zeros(R)

            for j in A:
                sum_mu[j] = self._calculate_sum_mu(j, mu)
                sum_mu_y[j] = self._calculate_sum_mu_y(j, mu)
                sum_neg_mu[j] = self._calculate_sum_neg_mu(j, mu)
                sum_neg_mu_y[j] = self._calculate_sum_neg_mu_y(j, mu)

                sensitivity[j] = (a1 - 1 + sum_mu_y[j]) / float(a1 + a2 - 2 + sum_mu[j])
                specificity[j] = (b1 - 1 + sum_neg_mu_y[j]) / float(b1 + b2 - 2 + sum_neg_mu[j])

            prevalence = self._calculate_prevalence(mu, p1, p2)
            difference = dict(mu)

            for i in data_dict:

                if i in supervised:
                    mu[i] = self._type_dict[i]
                else:
                    log_a = 0
                    log_b = 0

                    indices = [index for index, x in enumerate(data_dict[i]) if x < 2 and index in A]

                    for j in indices:
                        y = data_dict[i][j]
                        log_a += np.log((sensitivity[j] ** y) * ((1 - sensitivity[j]) ** (1 - y)))
                        log_b += np.log((specificity[j] ** (1 - y)) * ((1 - specificity[j]) ** y))

                    a[i] = np.exp(log_a)
                    b[i] = np.exp(log_b)

                    mu[i] = int(round((a[i] * prevalence) / (a[i] * prevalence + (b[i] * (1 - prevalence)))))

                difference[i] = abs(difference[i] - mu[i])

            mu_diff = sum(difference.values())

            if self.verbose:
                accuracy = data.correct_count(mu, type_dict) / float(N)
                print accuracy

        return mu, sensitivity, specificity

    def _calculate_prevalence(self, mu, p1, p2):
        sum_mu = sum([v for v in mu.values()])
        return (p1 - 1 + sum_mu) / float(p1 + p2 - 2 + len(mu))

    def _calculate_lambda_j(self, sensitivity, specificity, lambda_j):
        delta = self._calculate_delta_j(lambda_j)
        sigma = self._calculate_sigma_j(sensitivity, specificity, lambda_j)

        for j in range(len(lambda_j)):
            lambda_j[j] = delta[j] / float((sensitivity[j] + specificity[j] - 1) ** 2 + sigma[j])

        return lambda_j

    def _calculate_delta_j(self, lambda_j):
        delta = np.zeros(len(lambda_j))

        for j in range(len(lambda_j)):
            sqrt_j = np.sqrt(2 * np.pi * lambda_j[j])
            erf_j = erf(np.sqrt(lambda_j[j] / 2))
            delta[j] = 2 - (sqrt_j * erf_j) / (sqrt_j * erf_j + 2 * np.exp(-lambda_j[j] / 2) - 2)

        return delta

    def _calculate_sigma_j(self, sensitivity, specificity, lambda_j):
        sensitivity_deriv = np.zeros(len(lambda_j))
        specificity_deriv = np.zeros(len(lambda_j))

        for j in range(len(lambda_j)):
            sensitivity_deriv[j] = ((self._sum_mu_y[j] * (2 * sensitivity[j] - 1) - sensitivity[j] ** 2 * self._sum_mu[j]) / ((sensitivity[j] * (1 - sensitivity[j])) ** 2)) - lambda_j[j]
            specificity_deriv[j] = ((self._sum_neg_mu_y[j] * (2 * specificity[j] - 1) - specificity[j] ** 2 * self._sum_neg_mu[j]) / ((specificity[j] * (1 - specificity[j])) ** 2)) - lambda_j[j]

        a_blocks = [[[sensitivity_deriv[j], sensitivity_deriv[j]], [specificity_deriv[j], specificity_deriv[j]]] for j in range(len(lambda_j))]
        A = block_diag(*a_blocks)

        b_blocks = [[[lambda_j[j], lambda_j[j]], [lambda_j[j], lambda_j[j]]] for j in range(len(lambda_j))]
        B = block_diag(*b_blocks)

        H = A - B
        sigma = np.zeros(len(lambda_j))

        if cond(H) < 1 / sys.float_info.epsilon:
            inv_H = inv(A - B)
            sigma = [-inv_H[2 * j - 1][j - 1] - inv_H[2 * j - 1][2 * j] - inv_H[2 * j][2 * j - 1] - inv_H[2 * j][2 * j] for j in range(len(lambda_j))]
        elif self.verbose:
            print "Not using sigma"

        return sigma

    def _calculate_sum_mu(self, j, mu=None):
        if mu is not None:
            self._sum_mu[j] = sum([v if self._data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])

        return self._sum_mu[j]

    def _calculate_sum_neg_mu(self, j, mu=None):
        if mu is not None:
            self._sum_neg_mu[j] = sum([(1 - v) if self._data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])

        return self._sum_neg_mu[j]

    def _calculate_sum_mu_y(self, j, mu=None):
        if mu is not None:
            self._sum_mu_y[j] = sum([v * self._data_dict[k][j] if self._data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])

        return self._sum_mu_y[j]

    def _calculate_sum_neg_mu_y(self, j, mu=None):
        if mu is not None:
            self._sum_neg_mu_y[j] = sum([(1 - v) * (1 - self._data_dict[k][j]) if self._data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])
        return self._sum_neg_mu_y[j]


if __name__ == "__main__":
    engine_count, data_dict, type_dict = data.get_new_large_data()
    raykar = Raykar(engine_count, data_dict, type_dict)
    raykar.run_semi_supervised_method()
