import functools
import numpy as np
import random
import sys
from math import erf
from multiprocessing import Pool
from numpy.linalg import cond
from scipy.linalg import block_diag, inv

from algorithms import threshold
from utils import data
from utils.parallel import parmap


class Raykar:
    show_graphs = False
    verbose = True
    p = Pool()

    def __init__(self, engine_count, data_dict, type_dict):
        self._engine_count = engine_count
        self._data_dict = data_dict
        self._type_dict = type_dict

        self._sum_mu = np.zeros(engine_count)
        self._sum_neg_mu = np.zeros(engine_count)
        self._sum_mu_y = np.zeros(engine_count)
        self._sum_neg_mu_y = np.zeros(engine_count)

    def run_core_method(self):
        print "Raykar Method:"

        A = set(range(self._engine_count))
        self._print_results(*self._core_raykar(A, set()))

    def run_semi_supervised_method(self):
        print "Raykar (Semi-Supervised) Method:"

        supervised_proportion = 0.2
        supervised = set()

        for i in self._data_dict:
            if random.random() < supervised_proportion:
                supervised.add(i)

        A = set(range(self._engine_count))
        self._print_results(*self._core_raykar(A, supervised))

    def run_spammers_method(self):
        print "Raykar (Eliminating Spammers) Method:"

        N = len(self._data_dict)
        R = self._engine_count

        mu = {}
        sensitivity = []
        specificity = []

        A = set(range(R))
        old_A = set()

        lambda_j = np.ones(R) * 0.1 * N
        prune_threshold = 0.1 * N

        while A != old_A:
            old_A = set(A)

            mu, sensitivity, specificity = self._core_raykar(A, set())
            lambda_j = self._calculate_lambda_j(sensitivity, specificity, lambda_j)

            for i in old_A:
                if lambda_j[i] > prune_threshold:
                    if self.verbose:
                        print "Removed engine", i
                    A.remove(i)

        self._print_results(mu, sensitivity, specificity)

    def _print_results(self, results, learned_sensitivity, learned_specificity):
        accuracy = data.correct_count(results, self._type_dict) / float(len(self._data_dict))

        print "Accuracy:", accuracy

        if self.show_graphs:
            true_sensitivity, true_specificity = data.annotator_model(self._engine_count, self._data_dict, self._type_dict)
            data.sensitivity_graph(learned_sensitivity, true_sensitivity)
            data.specificity_graph(learned_specificity, true_specificity)

    def _core_raykar(self, A, supervised):
        # Initialise by majority voting
        mu = threshold.majority_vote(self._data_dict)

        # Initialisation
        N = len(mu)
        R = self._engine_count

        a1 = 3
        a2 = 2
        b1 = 3
        b2 = 2

        a = {}
        b = {}

        p1 = 2
        p2 = 2

        sensitivity = np.zeros(R)
        specificity = np.zeros(R)

        mu_diff = 1

        while mu_diff > 0:

            def calculate_mu_sums(j, self):
                sum_mu = 0
                sum_neg_mu = 0
                sum_mu_y = 0
                sum_neg_mu_y = 0

                for k, v in mu.items():
                    if self._data_dict[k][j] < 2:
                        sum_mu += v
                        sum_neg_mu += 1 - v
                        sum_mu_y += v * self._data_dict[k][j]
                        sum_neg_mu_y += (1 - v) * (1 - self._data_dict[k][j])

                return j, sum_mu, sum_neg_mu, sum_mu_y, sum_neg_mu_y

            results = parmap(functools.partial(calculate_mu_sums, self=self), A)

            for j, sum_mu, sum_neg_mu, sum_mu_y, sum_neg_mu_y in results:
                self._sum_mu[j] = sum_mu
                self._sum_neg_mu[j] = sum_neg_mu
                self._sum_mu_y[j] = sum_mu_y
                self._sum_neg_mu_y[j] = sum_neg_mu_y

            for j in A:
                sensitivity[j] = (a1 - 1 + self._sum_mu_y[j]) / float(a1 + a2 - 2 + self._sum_mu[j])
                specificity[j] = (b1 - 1 + self._sum_neg_mu_y[j]) / float(b1 + b2 - 2 + self._sum_neg_mu[j])

            prevalence = self._calculate_prevalence(mu, p1, p2)

            def calculate_mu(iv, self):
                i, v = iv
                if i in supervised:
                    mu_result = self._type_dict[i]
                else:
                    log_a = 0
                    log_b = 0

                    indices = [index for index, x in enumerate(v) if x < 2 and index in A]

                    for j in indices:
                        y = v[j]
                        log_a += np.log((sensitivity[j] ** y) * ((1 - sensitivity[j]) ** (1 - y)))
                        log_b += np.log((specificity[j] ** (1 - y)) * ((1 - specificity[j]) ** y))

                    a[i] = np.exp(log_a)
                    b[i] = np.exp(log_b)

                    mu_result = int(round((a[i] * prevalence) / (a[i] * prevalence + (b[i] * (1 - prevalence)))))

                diff = abs(mu[i] - mu_result)
                return i, mu_result, diff

            results = parmap(functools.partial(calculate_mu, self=self), self._data_dict.iteritems())

            mu_diff = 0

            for i, mu_result, diff in results:
                mu[i] = mu_result
                mu_diff += diff

            if self.verbose:
                accuracy = data.correct_count(mu, type_dict) / float(N)
                print accuracy

        return mu, sensitivity, specificity

    def _calculate_prevalence(self, mu, p1, p2):
        sum_mu = sum([v for v in mu.values()])
        return (p1 - 1 + sum_mu) / float(p1 + p2 - 2 + len(mu))

    def _calculate_lambda_j(self, sensitivity, specificity, lambda_j):
        delta = self._calculate_delta_j(lambda_j)
        sigma = self._calculate_sigma_j(sensitivity, specificity, lambda_j)

        for j in range(len(lambda_j)):
            lambda_j[j] = delta[j] / float((sensitivity[j] + specificity[j] - 1) ** 2 + sigma[j])

        return lambda_j

    def _calculate_delta_j(self, lambda_j):
        delta = np.zeros(len(lambda_j))

        for j in range(len(lambda_j)):
            sqrt_j = np.sqrt(2 * np.pi * lambda_j[j])
            erf_j = erf(np.sqrt(lambda_j[j] / 2))
            delta[j] = 2 - (sqrt_j * erf_j) / (sqrt_j * erf_j + 2 * np.exp(-lambda_j[j] / 2) - 2)

        return delta

    def _calculate_sigma_j(self, sensitivity, specificity, lambda_j):
        sensitivity_deriv = np.zeros(len(lambda_j))
        specificity_deriv = np.zeros(len(lambda_j))

        for j in range(len(lambda_j)):
            sensitivity_deriv[j] = (self._sum_mu_y[j] * (2 * sensitivity[j] - 1) - sensitivity[j] ** 2 * self._sum_mu[j]) / ((sensitivity[j] * (1 - sensitivity[j])) ** 2 + 0.0001)
            specificity_deriv[j] = (self._sum_neg_mu_y[j] * (2 * specificity[j] - 1) - specificity[j] ** 2 * self._sum_neg_mu[j]) / ((specificity[j] * (1 - specificity[j])) ** 2 + 0.0001)

        a_blocks = [[[sensitivity_deriv[j], -lambda_j[j]], [-lambda_j[j], specificity_deriv[j]]] for j in range(len(lambda_j))]
        A = block_diag(*a_blocks)

        b_blocks = [[[lambda_j[j], lambda_j[j]], [lambda_j[j], lambda_j[j]]] for j in range(len(lambda_j))]
        B = block_diag(*b_blocks)

        H = A - B
        sigma = np.zeros(len(lambda_j))

        if cond(H) < 1 / sys.float_info.epsilon:
            inv_H = inv(A - B)
            sigma = [-inv_H[2 * j - 1][j - 1] - inv_H[2 * j - 1][2 * j] - inv_H[2 * j][2 * j - 1] - inv_H[2 * j][2 * j] for j in range(len(lambda_j))]
        elif self.verbose:
            print "Not using sigma"

        return sigma


if __name__ == "__main__":
    engine_count, data_dict, type_dict = data.get_ransomware_data()
    raykar = Raykar(engine_count, data_dict, type_dict)
