import functools
import json
import numpy as np
import os
import sys
from hashlib import sha1
from math import erf
from multiprocessing import Pool
from numpy.linalg import cond
from scipy.linalg import block_diag, inv

from algorithms import threshold
from utils import data
from utils.parallel import parmap


class Raykar:
    p = Pool()

    def __init__(self, engine_count, data_dict, type_dict, verbose=False, show_graphs=False, train_test=False, save=True):
        self._engine_count = engine_count
        self._data_dict = data_dict
        self._type_dict = type_dict

        self._hash = str(engine_count) + sha1(repr((frozenset(type_dict.items())))).hexdigest()

        self._train_test = train_test

        self._train_data = {}
        self._test_data = {}

        self._sum_mu = np.zeros(engine_count)
        self._sum_neg_mu = np.zeros(engine_count)
        self._sum_mu_y = np.zeros(engine_count)
        self._sum_neg_mu_y = np.zeros(engine_count)

        self._training_proportion = 0.8
        self._repeats = 10 if train_test else 1

        self._verbose = verbose
        self._show_graphs = show_graphs
        self._save = not train_test and save

    def run_core_method(self):
        print "Raykar Method:"
        self._run_train_test(self._core_method)

    def _core_method(self):
        A = set(range(self._engine_count))
        results, prob_results, sensitivity, specificity = self._core_raykar(A, set())
        self._print_results(results[-1], sensitivity, specificity)

        return results, sensitivity, specificity, A

    def run_semi_supervised_method(self):
        print "Raykar (Semi-Supervised) Method:"

        if self._train_test:
            self._train_data, self._test_data = data.train_test_data(self._data_dict, self._training_proportion)
        else:
            self._train_data = self._data_dict
            self._test_data = self._data_dict

        supervised_results = []
        supervised = []

        for i in range(20):
            supervised_proportion = i * 0.05
            print "Using supervised proportion:", supervised_proportion
            supervised = data.split_data(self._train_data.keys(), supervised_proportion, supervised)
            A = set(range(self._engine_count))

            train_results, _, sensitivity, specificity = self._core_raykar(A, supervised)
            prevalence = self._calculate_prevalence(train_results[-1])
            test_results = {k: self._calculate_posterior(v, sensitivity, specificity, A, prevalence) for k, v in self._test_data.iteritems()}
            accuracy = data.correct_count(test_results, self._type_dict) / float(len(self._test_data))
            supervised_results.append((supervised_proportion, accuracy))
            print "Accuracy:", accuracy

        if self._show_graphs:
            data.supervised_graph(*zip(*supervised_results))

    def run_spammers_method(self):
        print "Raykar (Eliminating Spammers) Method:"
        self._run_train_test(self._spammers_method)

    def _spammers_method(self):
        N = len(self._train_data)
        R = self._engine_count

        results=[]
        sensitivity = []
        specificity = []

        A = set(range(R))
        old_A = set()

        lambda_j = np.ones(R) * 0.1 * N
        prune_threshold = 0.1 * N

        while A != old_A:
            old_A = set(A)

            results, _, sensitivity, specificity = self._core_raykar(A, set())

            lambda_j = self._calculate_lambda_j(sensitivity, specificity, lambda_j)

            for i in old_A:
                if lambda_j[i] > prune_threshold:
                    if self._verbose:
                        print "Removed engine", i
                    A.remove(i)

        self._print_results(results[-1], sensitivity, specificity)

        return results, sensitivity, specificity, A

    def run_annotators_method(self):
        print "Raykar (Progressive Annotators) Method:"

        self._train_data = self._data_dict
        self._test_data = self._data_dict

        A = set(range(self._engine_count))
        results, _, sensitivity, specificity = self._core_raykar(A, set())

        sorted_indices = np.argsort(sensitivity)[::-1]
        sorted_engines = np.array(range(self._engine_count))[sorted_indices]

        accuracies = []
        false_positive_rates = []

        R = self._engine_count

        for i in range(R):
            print "Using %i best engine(s):" % (i + 1)
            engines = set(sorted_engines[0:i + 1])
            new_results, _, _, _ = self._core_raykar(engines, set())
            accuracy = data.correct_count(new_results[-1], self._type_dict) / float(len(self._test_data))
            accuracies.append(accuracy)
            fpr = data.fpr(new_results[-1], self._type_dict)
            false_positive_rates.append(fpr)
            print "Accuracy:", accuracy

        if self._show_graphs:
            data.annotator_graph(accuracies, R)

    def _run_train_test(self, runner):
        comp_results = []

        for i in range(self._repeats):
            if self._train_test:
                self._train_data, self._test_data = data.train_test_data(self._data_dict, self._training_proportion)
            else:
                self._train_data = self._data_dict
                self._test_data = self._data_dict

            results, sensitivity, specificity, A = runner()
            test_results = self._test_results(results, sensitivity, specificity, A)
            comp_results.append(data.calculate_results(test_results, self._type_dict))

        self._print_comp_results(comp_results)

    def _print_results(self, results, learned_sensitivity, learned_specificity):
        accuracy = data.correct_count(results, self._type_dict) / float(len(results))

        print "Accuracy:", accuracy

        if self._show_graphs:
            true_sensitivity, true_specificity = data.annotator_model(self._engine_count, self._train_data, self._type_dict)
            data.sensitivity_graph(learned_sensitivity, true_sensitivity)
            data.specificity_graph(learned_specificity, true_specificity)

    def _print_comp_results(self, comp_results):
        avg_error, avg_fpr, avg_fnr = map(lambda x: x / float(len(comp_results)), map(sum, zip(*comp_results)))

        print "Average Error Rate", avg_error
        print "Average False Positive Rate", avg_fpr
        print "Average False Negative Rate", avg_fnr

    def _test_results(self, results, sensitivity, specificity, A):
        prevalence = self._calculate_prevalence(results[-1])
        return {k: 1 if self._calculate_posterior(v, sensitivity, specificity, A, prevalence) > 0.5 else 0 for k, v in self._test_data.iteritems()}

    def _hash_dict(self, dict):
        return sha1(json.dumps(dict.items(), sort_keys=True)).hexdigest()

    def _generate_hash(self, A, supervised):
        return self._hash_dict(self._train_data) + "_" +\
               self._hash_dict(self._test_data) + "_" +\
               sha1(repr(frozenset(A))).hexdigest() + "_" +\
               sha1(repr(frozenset(supervised))).hexdigest() + "_" +\
               self._hash

    def _core_raykar(self, A, supervised):
        filename = "saved/raykar" + "_" + self._generate_hash(A, supervised)
        filename_npz = filename + ".npz"
        # filename_npy = filename + ".npy"

        if self._save and os.path.exists(filename_npz):
            npz = np.load(filename_npz)
            mus = npz['mus']
            mu_probs = npz['mu_probs']
            sensitivity = npz['sensitivity']
            specificity = npz['specificity']

            self._sum_mu = npz['sum_mu']
            self._sum_mu_y = npz['sum_mu_y']
            self._sum_neg_mu = npz['sum_neg_mu']
            self._sum_neg_mu_y = npz['sum_neg_mu_y']

            # mus = results[0]
            # mu_probs = results[1]
            # sensitivity = results[2]
            # specificity = results[3]
            #
            # self._sum_mu = results[4]
            # self._sum_mu_y = results[5]
            # self._sum_neg_mu = results[6]
            # self._sum_neg_mu_y = results[7]

            if self._verbose:
                for mu in mus[1:]:
                    accuracy = data.correct_count(mu, self._type_dict) / float(len(mu))
                    print accuracy

            return mus, mu_probs, sensitivity, specificity

        # Initialise by majority voting
        mu = threshold.Threshold(self._train_data, self._type_dict).majority_vote()
        mus = [mu]
        mu_probs = [{key: 1 for key in mu}]

        # Initialisation
        N = len(mu)
        R = self._engine_count

        a1 = 3
        a2 = 2
        b1 = 3
        b2 = 2

        sensitivity = np.zeros(R)
        specificity = np.zeros(R)

        mu_diff = 1
        mu_eps = 0.0001

        gamma_threshold = 0.5

        while mu_diff > mu_eps:

            def calculate_mu_sums(j, self):
                sum_mu = 0
                sum_neg_mu = 0
                sum_mu_y = 0
                sum_neg_mu_y = 0

                for k, v in mu.iteritems():
                    if self._train_data[k][j] < 2:
                        sum_mu += v
                        sum_neg_mu += 1 - v
                        sum_mu_y += v * self._train_data[k][j]
                        sum_neg_mu_y += (1 - v) * (1 - self._train_data[k][j])

                return j, sum_mu, sum_neg_mu, sum_mu_y, sum_neg_mu_y

            results = parmap(functools.partial(calculate_mu_sums, self=self), A)

            for j, sum_mu, sum_neg_mu, sum_mu_y, sum_neg_mu_y in results:
                self._sum_mu[j] = sum_mu
                self._sum_neg_mu[j] = sum_neg_mu
                self._sum_mu_y[j] = sum_mu_y
                self._sum_neg_mu_y[j] = sum_neg_mu_y

            for j in A:
                sensitivity[j] = (a1 - 1 + self._sum_mu_y[j]) / float(a1 + a2 - 2 + self._sum_mu[j])
                specificity[j] = (b1 - 1 + self._sum_neg_mu_y[j]) / float(b1 + b2 - 2 + self._sum_neg_mu[j])

            prevalence = self._calculate_prevalence(mu)

            def calculate_mu(iv, self):
                i, v = iv
                if i in supervised:
                    mu_result = self._type_dict[i]
                    mu_prob = 1
                else:
                    mu_prob = self._calculate_posterior(v, sensitivity, specificity, A, prevalence)
                    mu_result = 1 if mu_prob > gamma_threshold else 0

                diff = abs(mu[i] - mu_result)
                return i, mu_result, mu_prob, diff

            results = parmap(functools.partial(calculate_mu, self=self), self._train_data.iteritems())

            mu_diff = 0
            mu_prob_dict = {}

            for i, mu_result, mu_prob, diff in results:
                mu_prob_dict[i] = mu_prob
                mu[i] = mu_result
                mu_diff += diff

            if self._verbose:
                accuracy = data.correct_count(mu, self._type_dict) / float(len(mu))
                print accuracy

            mus.append(dict(mu))
            mu_probs.append(mu_prob_dict)

        if self._save:
            if not os.path.exists("saved/"):
                os.makedirs("saved/")

            np.savez_compressed(filename, mus=mus, mu_probs=mu_probs, sensitivity=sensitivity, specificity=specificity,
                     sum_mu=self._sum_mu, sum_mu_y=self._sum_mu_y, sum_neg_mu=self._sum_neg_mu,
                     sum_neg_mu_y=self._sum_neg_mu_y)

            # np.save(filename, (mus, mu_probs, sensitivity, specificity, self._sum_mu, self._sum_mu_y, self._sum_neg_mu, self._sum_neg_mu_y))

        return mus, mu_probs, sensitivity, specificity

    def _calculate_prevalence(self, mu):
        p1 = 2
        p2 = 2
        sum_mu = sum([v for v in mu.values()])
        return (p1 - 1 + sum_mu) / float(p1 + p2 - 2 + len(mu))

    def _calculate_lambda_j(self, sensitivity, specificity, lambda_j):
        delta = self._calculate_delta_j(lambda_j)
        sigma = self._calculate_sigma_j(sensitivity, specificity, lambda_j)

        for j in range(len(lambda_j)):
            lambda_j[j] = delta[j] / float((sensitivity[j] + specificity[j] - 1) ** 2 + sigma[j])

        return lambda_j

    def _calculate_delta_j(self, lambda_j):
        delta = np.zeros(len(lambda_j))

        for j in range(len(lambda_j)):
            sqrt_j = np.sqrt(2 * np.pi * lambda_j[j])
            erf_j = erf(np.sqrt(lambda_j[j] / 2))
            delta[j] = 2 - (sqrt_j * erf_j) / (sqrt_j * erf_j + 2 * np.exp(-lambda_j[j] / 2) - 2)

        return delta

    def _calculate_sigma_j(self, sensitivity, specificity, lambda_j):
        sensitivity_deriv = np.zeros(len(lambda_j))
        specificity_deriv = np.zeros(len(lambda_j))

        for j in range(len(lambda_j)):
            sensitivity_deriv[j] = (self._sum_mu_y[j] * (2 * sensitivity[j] - 1) - sensitivity[j] ** 2 * self._sum_mu[j]) / ((sensitivity[j] * (1 - sensitivity[j])) ** 2 + 0.0001)
            specificity_deriv[j] = (self._sum_neg_mu_y[j] * (2 * specificity[j] - 1) - specificity[j] ** 2 * self._sum_neg_mu[j]) / ((specificity[j] * (1 - specificity[j])) ** 2 + 0.0001)

        a_blocks = [[[sensitivity_deriv[j], -lambda_j[j]], [-lambda_j[j], specificity_deriv[j]]] for j in range(len(lambda_j))]
        A = block_diag(*a_blocks)

        b_blocks = [[[lambda_j[j], lambda_j[j]], [lambda_j[j], lambda_j[j]]] for j in range(len(lambda_j))]
        B = block_diag(*b_blocks)

        H = A - B
        sigma = np.zeros(len(lambda_j))

        if cond(H) < 1 / sys.float_info.epsilon:
            inv_H = inv(A - B)
            sigma = [-inv_H[2 * j - 1][j - 1] - inv_H[2 * j - 1][2 * j] - inv_H[2 * j][2 * j - 1] - inv_H[2 * j][2 * j] for j in range(len(lambda_j))]
        elif self._verbose:
            print "Not using sigma"

        return sigma

    def _calculate_posterior(self, data, sensitivity, specificity, valid_engines, prevalence):
        indices = [index for index, x in enumerate(data) if x < 2 and index in valid_engines]

        ys = np.array(data)[indices]
        sensitivities = sensitivity[indices]
        specificities = specificity[indices]
        neg_ys = 1 - ys

        a = np.exp(np.sum(np.log((sensitivities ** ys) * ((1 - sensitivities) ** neg_ys))))
        b = np.exp(np.sum(np.log((specificities ** neg_ys) * ((1 - specificities) ** ys))))

        mu_result = (a * prevalence) / (a * prevalence + (b * (1 - prevalence)))
        return mu_result


if __name__ == "__main__":
    engine_count, data_dict, type_dict = data.get_new_large_data()
    raykar = Raykar(engine_count, data_dict, type_dict)
    raykar.run_semi_supervised_method()
