import functools
import numpy as np
import sys
from math import erf
from multiprocessing import Pool
from numpy.linalg import cond
from scipy.linalg import block_diag, inv

from algorithms import threshold
from utils import data
from utils.parallel import parmap


class Raykar:
    p = Pool()

    def __init__(self, engine_count, data_dict, type_dict, verbose=False, show_graphs=False):
        self._engine_count = engine_count
        self._data_dict = data_dict
        self._type_dict = type_dict

        self._train_data = {}
        self._test_data = {}

        self._sum_mu = np.zeros(engine_count)
        self._sum_neg_mu = np.zeros(engine_count)
        self._sum_mu_y = np.zeros(engine_count)
        self._sum_neg_mu_y = np.zeros(engine_count)

        self._verbose = verbose
        self._show_graphs = show_graphs

    def run_core_method(self):
        print "Raykar Method:"

        self._train_data = self._data_dict
        self._test_data = self._data_dict

        A = set(range(self._engine_count))
        results, sensitivity, specificity = self._core_raykar(A, set())
        self._print_results(results[-1], sensitivity, specificity)
        return results

    def run_semi_supervised_method(self):
        print "Raykar (Semi-Supervised) Method:"

        self._train_data = {}
        self._test_data = {}

        training_proportion = 0.8
        self._setup_train_test_data(training_proportion)

        supervised_results = []
        supervised = []

        for i in range(20):
            supervised_proportion = i * 0.05
            print "Using supervised proportion:", supervised_proportion
            supervised = data.split_data(self._train_data.keys(), supervised_proportion, supervised)
            A = set(range(self._engine_count))

            train_results, sensitivity, specificity = self._core_raykar(A, supervised)
            prevalence = self._calculate_prevalence(train_results[-1])
            test_results = {k: self._calculate_posterior(v, sensitivity, specificity, A, prevalence) for k, v in self._test_data.iteritems()}
            accuracy = data.correct_count(test_results, self._type_dict) / float(len(self._test_data))
            supervised_results.append((supervised_proportion, accuracy))
            print "Accuracy:", accuracy

        if self._show_graphs:
            data.supervised_graph(*zip(*supervised_results))

    def run_spammers_method(self):
        print "Raykar (Eliminating Spammers) Method:"

        # self._train_data = self._data_dict
        # self._test_data = self._data_dict

        self._setup_train_test_data(0.8)

        N = len(self._train_data)
        R = self._engine_count

        results=[]
        sensitivity = []
        specificity = []

        A = set(range(R))
        old_A = set()

        lambda_j = np.ones(R) * 0.1 * N
        prune_threshold = 0.1 * N

        while A != old_A:
            old_A = set(A)

            results, sensitivity, specificity = self._core_raykar(A, set())
            lambda_j = self._calculate_lambda_j(sensitivity, specificity, lambda_j)

            for i in old_A:
                if lambda_j[i] > prune_threshold:
                    if self._verbose:
                        print "Removed engine", i
                    A.remove(i)

            prevalence = self._calculate_prevalence(results[-1])
            test_results = {k: self._calculate_posterior(v, sensitivity, specificity, A, prevalence) for k, v in self._test_data.iteritems()}
            accuracy = data.correct_count(test_results, self._type_dict) / float(len(self._test_data))
            print "Accuracy (Test Data):", accuracy

        self._print_results(results[-1], sensitivity, specificity)

    def run_annotators_method(self):
        print "Raykar (Progressive Annotators) Method:"

        self._train_data = self._data_dict
        self._test_data = self._data_dict

        A = set(range(self._engine_count))
        results, sensitivity, specificity = self._core_raykar(A, set())

        sorted_indices = np.argsort(sensitivity)[::-1]
        sorted_engines = np.array(range(self._engine_count))[sorted_indices]

        accuracies = []

        R = 15

        for i in range(R):
            print "Using %i best engine(s):" % (i + 1)
            engines = set(sorted_engines[0:i + 1])
            new_results, _, _ = self._core_raykar(engines, set())
            accuracy = data.correct_count(new_results[-1], self._type_dict) / float(len(self._test_data))
            accuracies.append(accuracy)
            print "Accuracy:", accuracy

        if self._show_graphs:
            data.annotator_graph(accuracies, R)

    def _print_results(self, results, learned_sensitivity, learned_specificity):
        accuracy = data.correct_count(results, self._type_dict) / float(len(self._test_data))

        print "Accuracy:", accuracy

        if self._show_graphs:
            true_sensitivity, true_specificity = data.annotator_model(self._engine_count, self._train_data, self._type_dict)
            data.sensitivity_graph(learned_sensitivity, true_sensitivity)
            data.specificity_graph(learned_specificity, true_specificity)

    def _setup_train_test_data(self, training_proportion):
        training_data = np.random.choice(self._data_dict.keys(), len(self._data_dict) * training_proportion)

        for k, v in self._data_dict.iteritems():
            if k in training_data:
                self._train_data[k] = v
            else:
                self._test_data[k] = v

    def _core_raykar(self, A, supervised):
        # Initialise by majority voting
        mu = threshold.Threshold(self._train_data, self._type_dict).majority_vote()
        mus = [mu]

        # Initialisation
        N = len(mu)
        R = self._engine_count

        a1 = 3
        a2 = 2
        b1 = 3
        b2 = 2

        sensitivity = np.zeros(R)
        specificity = np.zeros(R)

        mu_diff = 1

        while mu_diff > 0:

            def calculate_mu_sums(j, self):
                sum_mu = 0
                sum_neg_mu = 0
                sum_mu_y = 0
                sum_neg_mu_y = 0

                for k, v in mu.iteritems():
                    if self._train_data[k][j] < 2:
                        sum_mu += v
                        sum_neg_mu += 1 - v
                        sum_mu_y += v * self._train_data[k][j]
                        sum_neg_mu_y += (1 - v) * (1 - self._train_data[k][j])

                return j, sum_mu, sum_neg_mu, sum_mu_y, sum_neg_mu_y

            results = parmap(functools.partial(calculate_mu_sums, self=self), A)

            for j, sum_mu, sum_neg_mu, sum_mu_y, sum_neg_mu_y in results:
                self._sum_mu[j] = sum_mu
                self._sum_neg_mu[j] = sum_neg_mu
                self._sum_mu_y[j] = sum_mu_y
                self._sum_neg_mu_y[j] = sum_neg_mu_y

            for j in A:
                sensitivity[j] = (a1 - 1 + self._sum_mu_y[j]) / float(a1 + a2 - 2 + self._sum_mu[j])
                specificity[j] = (b1 - 1 + self._sum_neg_mu_y[j]) / float(b1 + b2 - 2 + self._sum_neg_mu[j])

            prevalence = self._calculate_prevalence(mu)

            def calculate_mu(iv, self):
                i, v = iv
                if i in supervised:
                    mu_result = self._type_dict[i]
                else:
                    mu_result = self._calculate_posterior(v, sensitivity, specificity, A, prevalence)

                diff = abs(mu[i] - mu_result)
                return i, mu_result, diff

            results = parmap(functools.partial(calculate_mu, self=self), self._train_data.iteritems())

            mu_diff = 0

            for i, mu_result, diff in results:
                mu[i] = mu_result
                mu_diff += diff

            if self._verbose:
                accuracy = data.correct_count(mu, self._type_dict) / float(N)
                print accuracy

            mus.append(dict(mu))

        return mus, sensitivity, specificity

    def _calculate_prevalence(self, mu):
        p1 = 2
        p2 = 2
        sum_mu = sum([v for v in mu.values()])
        return (p1 - 1 + sum_mu) / float(p1 + p2 - 2 + len(mu))

    def _calculate_lambda_j(self, sensitivity, specificity, lambda_j):
        delta = self._calculate_delta_j(lambda_j)
        sigma = self._calculate_sigma_j(sensitivity, specificity, lambda_j)

        for j in range(len(lambda_j)):
            lambda_j[j] = delta[j] / float((sensitivity[j] + specificity[j] - 1) ** 2 + sigma[j])

        return lambda_j

    def _calculate_delta_j(self, lambda_j):
        delta = np.zeros(len(lambda_j))

        for j in range(len(lambda_j)):
            sqrt_j = np.sqrt(2 * np.pi * lambda_j[j])
            erf_j = erf(np.sqrt(lambda_j[j] / 2))
            delta[j] = 2 - (sqrt_j * erf_j) / (sqrt_j * erf_j + 2 * np.exp(-lambda_j[j] / 2) - 2)

        return delta

    def _calculate_sigma_j(self, sensitivity, specificity, lambda_j):
        sensitivity_deriv = np.zeros(len(lambda_j))
        specificity_deriv = np.zeros(len(lambda_j))

        for j in range(len(lambda_j)):
            sensitivity_deriv[j] = (self._sum_mu_y[j] * (2 * sensitivity[j] - 1) - sensitivity[j] ** 2 * self._sum_mu[j]) / ((sensitivity[j] * (1 - sensitivity[j])) ** 2 + 0.0001)
            specificity_deriv[j] = (self._sum_neg_mu_y[j] * (2 * specificity[j] - 1) - specificity[j] ** 2 * self._sum_neg_mu[j]) / ((specificity[j] * (1 - specificity[j])) ** 2 + 0.0001)

        a_blocks = [[[sensitivity_deriv[j], -lambda_j[j]], [-lambda_j[j], specificity_deriv[j]]] for j in range(len(lambda_j))]
        A = block_diag(*a_blocks)

        b_blocks = [[[lambda_j[j], lambda_j[j]], [lambda_j[j], lambda_j[j]]] for j in range(len(lambda_j))]
        B = block_diag(*b_blocks)

        H = A - B
        sigma = np.zeros(len(lambda_j))

        if cond(H) < 1 / sys.float_info.epsilon:
            inv_H = inv(A - B)
            sigma = [-inv_H[2 * j - 1][j - 1] - inv_H[2 * j - 1][2 * j] - inv_H[2 * j][2 * j - 1] - inv_H[2 * j][2 * j] for j in range(len(lambda_j))]
        elif self._verbose:
            print "Not using sigma"

        return sigma

    def _calculate_posterior(self, data, sensitivity, specificity, valid_engines, prevalence):
        indices = [index for index, x in enumerate(data) if x < 2 and index in valid_engines]

        ys = np.array(data)[indices]
        sensitivities = np.array(sensitivity)[indices]
        specificities = np.array(specificity)[indices]
        neg_ys = 1 - ys

        a = np.exp(np.sum(np.log((sensitivities ** ys) * ((1 - sensitivities) ** neg_ys))))
        b = np.exp(np.sum(np.log((specificities ** neg_ys) * ((1 - specificities) ** ys))))

        mu_result = (a * prevalence) / (a * prevalence + (b * (1 - prevalence)))
        return mu_result


if __name__ == "__main__":
    engine_count, data_dict, type_dict = data.get_new_large_data()
    raykar = Raykar(engine_count, data_dict, type_dict)
    raykar.run_semi_supervised_method()
