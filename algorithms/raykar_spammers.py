import numpy as np
from math import erf

from algorithms import threshold
from utils import data

show_graphs = True
verbose = True


def run_raykar(engine_count, data_dict, type_dict):
    print "Raykar (Eliminating Spammers) Method:"

    results, learned_sensitivity, learned_specificity = raykar(engine_count, data_dict, type_dict)
    accuracy = data.correct_count(results, type_dict) / float(len(data_dict))

    print "Accuracy:", accuracy

    if show_graphs:
        true_sensitivity, true_specificity = data.annotator_model(engine_count, data_dict, type_dict)
        data.sensitivity_graph(learned_sensitivity, true_sensitivity)
        data.specificity_graph(learned_specificity, true_specificity)


def raykar(engine_count, data_dict, type_dict):

    # Initialise by majority voting
    mu = threshold.majority_vote(data_dict)

    # Initialisation
    N = len(mu)
    R = engine_count

    A = set(range(R))

    a1 = 3
    a2 = 2
    b1 = 3
    b2 = 2

    p1 = 2
    p2 = 2

    sensitivity = np.zeros(R)
    specificity = np.zeros(R)

    a = {}
    b = {}

    old_A = set()

    lambda_j = np.ones(R) * 0.1 * N
    prune_threshold = 0.1 * N

    while A != old_A:
        old_A = set(A)
        mu_diff = 1

        while mu_diff > 0:
            # EM iteration
            for j in A:
                sum_mu = sum([v if data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])
                sum_neg_mu = sum([(1 - v) if data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])

                sum_mu_y = sum([v * data_dict[k][j] if data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])
                sum_neg_mu_y = sum([(1 - v) * (1 - data_dict[k][j]) if data_dict[k][j] < 2 else 0 for k, v in mu.iteritems()])

                sensitivity[j] = (a1 - 1 + sum_mu_y) / float(a1 + a2 - 2 + sum_mu)
                specificity[j] = (b1 - 1 + sum_neg_mu_y) / float(b1 + b2 - 2 + sum_neg_mu)

            prevalence = calculate_prevalence(mu, p1, p2)
            difference = dict(mu)

            for i in data_dict:

                log_a = 0
                log_b = 0

                indices = [index for index, x in enumerate(data_dict[i]) if x < 2 and index in A]

                for j in indices:
                    y = data_dict[i][j]
                    log_a += np.log((sensitivity[j] ** y) * ((1 - sensitivity[j]) ** (1 - y)))
                    log_b += np.log((specificity[j] ** (1 - y)) * ((1 - specificity[j]) ** y))

                a[i] = np.exp(log_a)
                b[i] = np.exp(log_b)

                mu[i] = int(round((a[i] * prevalence) / (a[i] * prevalence + (b[i] * (1 - prevalence)))))
                difference[i] = abs(difference[i] - mu[i])

            mu_diff = sum(difference.values())

            if verbose:
                accuracy = data.correct_count(mu, type_dict) / float(N)
                print accuracy

        for j in A:
            lambda_j[j] = calculate_lambda_j(sensitivity[j], specificity[j], lambda_j[j])

        print lambda_j

        for i in old_A:
            if lambda_j[i] > prune_threshold:
                print "Removed engine", i
                A.remove(i)

    return mu, sensitivity, specificity


def calculate_prevalence(mu, p1, p2):
    sum_mu = sum([v for v in mu.values()])
    return (p1 - 1 + sum_mu) / float(p1 + p2 - 2 + len(mu))


def calculate_lambda_j(sensitivity, specificity, lambda_j):
    return calculate_delta_j(lambda_j) / float((sensitivity + specificity - 1) ** 2)


def calculate_delta_j(lambda_j):
    sqrt_j = np.sqrt(2 * np.pi * lambda_j)
    erf_j = erf(np.sqrt(lambda_j / 2))
    return 2 - (sqrt_j * erf_j) / (sqrt_j * erf_j + 2 * np.exp(-lambda_j / 2) - 2)


if __name__ == "__main__":
    engine_count, data_dict, type_dict = data.get_old_large_data()
    run_raykar(engine_count, data_dict, type_dict)











