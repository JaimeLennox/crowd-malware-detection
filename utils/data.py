import numpy as np

import matplotlib.pyplot as plt


def create_data_dict(data_file):
    with open(data_file) as file:
        lines = [line.rstrip(';\r\n') for line in file]

    data_list = map(lambda x: x.split(';'), lines)
    data_dict = {}

    for data in data_list:
        data_dict[data[0]] = map(int, data[1:])

    return data_dict


def count_antivirus_engines(engine_file):
    count = 0

    with open(engine_file) as engines:
        for line in engines:
            if line.strip():
                count += 1

    return count


def get_malware_proportions(result_values):
    return result_values.count(0), result_values.count(1)


def sensitivity_graph(learned_sensitivity, true_sensitivity):
    plt.xlim(0, 1)
    plt.ylim(0, 1)

    plt.xlabel("True Sensitivity")
    plt.ylabel("Learned Sensitivity")

    # Colour abnormally different results red, else blue
    colours = ['r' if abs(learned_sensitivity[i] - true_sensitivity[i]) > 0.5 else 'b' for i in range(len(true_sensitivity))]

    plt.scatter(true_sensitivity, learned_sensitivity, c=colours)
    plt.plot((0, 1), 'r-')
    plt.show()


def specificity_graph(learned_specificity, true_specificity):
    plt.xlim(0, 1)
    plt.ylim(0, 1)

    plt.xlabel("True Specificity")
    plt.ylabel("Learned Specificity")

    colours = ['r' if abs(learned_specificity[i] - true_specificity[i]) > 0.5 else 'b' for i in range(len(true_specificity))]

    plt.scatter(true_specificity, learned_specificity, c=colours)
    plt.plot((0, 1), 'r-')
    plt.show()


def supervised_graph(supervised_proportion, accuracy):
    plt.xlim(0, 1)
    plt.ylim(min(accuracy) - 0.01, max(accuracy) + 0.01)

    plt.xlabel("Supervised Proportion")
    plt.ylabel("Accuracy")

    plt.scatter(supervised_proportion, accuracy)
    plt.show()


def roc_graph(*results):
    colours = iter(['r', 'b', 'g'])

    for data in results:
        print data
        plt.scatter(*zip(*data), color=next(colours))

    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")

    plt.xscale('log')

    plt.show()


def annotator_model(engine_count, data_dict, type_dict):
    sensitivity = np.zeros(engine_count)
    specificity = np.zeros(engine_count)
    malware_count = np.zeros(engine_count)
    goodware_count = np.zeros(engine_count)

    for k, v in data_dict.iteritems():
        for i in range(engine_count):
            if v[i] < 2:
                sensitivity[i] += 1 if v[i] == 1 and type_dict[k] == 1 else 0
                specificity[i] += 1 if v[i] == 0 and type_dict[k] == 0 else 0

                if type_dict[k] == 1:
                    malware_count[i] += 1
                else:
                    goodware_count[i] += 1

    sensitivity = [sensitivity[i] / malware_count[i] if malware_count[i] != 0 else 0 for i in range(len(sensitivity))]
    specificity = [specificity[i] / goodware_count[i] if goodware_count[i] != 0 else 0 for i in range(len(specificity))]

    return sensitivity, specificity


def correct_count(results, type_dict):
    return sum([1 if results[result] == type_dict[result] else 0 for result in results])


def roc_results(results, type_dict):
    true_positives = 0
    false_positives = 0

    for key in results:
        true_positives += 1 if results[key] == 1 and type_dict[key] == 1 else 0
        false_positives += 1 if results[key] == 1 and type_dict[key] == 0 else 0

    true_positives /= float(len(results))
    false_positives /= float(len(results))

    return false_positives, true_positives


def split_data(data, proportion, existing=[]):
    data = [item for item in data if item not in existing]
    result = np.random.choice(data, len(data) * proportion)
    return np.concatenate((result, existing))


def get_ransomware_data():
    return get_data(
        'datasets/ransomware/AVnames.txt',
        'datasets/ransomware/matrix-antivirus-ransomware.txt',
        'datasets/ransomware/matrix-antivirus-goodware.txt'
    )


def get_old_large_data():
    return get_data(
        'datasets/old_large/engines.txt',
        'datasets/old_large/matrix-antivirus-malware.txt',
        'datasets/old_large/matrix-antivirus-goodware.txt'
    )

def get_new_large_data():
    return get_data(
        'datasets/new_large/engines.txt',
        'datasets/new_large/matrix-antivirus-malware.txt',
        'datasets/new_large/matrix-antivirus-goodware.txt'
    )


def get_data(engine_file, malware_file, goodware_file):
    engine_count = count_antivirus_engines(engine_file)
    ransomware_dict = create_data_dict(malware_file)
    goodware_dict = create_data_dict(goodware_file)

    data_dict = dict(ransomware_dict.items() + goodware_dict.items())

    type_dict = dict([(key, 1) for key in ransomware_dict] + [(key, 0) for key in goodware_dict])

    return engine_count, data_dict, type_dict

